{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "from functools import partial\n",
    "\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib.parallel import parallel_backend\n",
    "from loguru import logger as loguru_logger\n",
    "from wildfires.qstat import get_ncpus\n",
    "\n",
    "from empirical_fire_modelling.configuration import Experiment\n",
    "from empirical_fire_modelling.data import (\n",
    "    get_data,\n",
    "    get_endog_exog_mask,\n",
    "    get_experiment_split_data,\n",
    "    get_first_cube_datetimes,\n",
    ")\n",
    "from empirical_fire_modelling.logging_config import enable_logging\n",
    "from empirical_fire_modelling.model import get_model, get_model_scores\n",
    "from empirical_fire_modelling.utils import tqdm\n",
    "\n",
    "mpl.rc_file(\"../matplotlibrc\")\n",
    "\n",
    "loguru_logger.enable(\"alepython\")\n",
    "loguru_logger.remove()\n",
    "loguru_logger.add(sys.stderr, level=\"WARNING\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "enable_logging(level=\"WARNING\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Collapsing a non-contiguous coordinate.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*DEFAULT_SPHERICAL_EARTH_RADIUS.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*guessing contiguous bounds.*\")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", 'Setting feature_perturbation = \"tree_path_dependent\".*'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment[\"15VEG_FAPAR_MON\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operate on cached data only.\n",
    "get_experiment_split_data.check_in_store(experiment)\n",
    "X_train, X_test, y_train, y_test = get_experiment_split_data(experiment)\n",
    "\n",
    "# Operate on cached data only.\n",
    "get_data(experiment, cache_check=True)\n",
    "endog_data, exog_data, master_mask = get_endog_exog_mask(experiment)\n",
    "\n",
    "# Operate on cached fitted models only.\n",
    "get_model(X_train, y_train, cache_check=True)\n",
    "model = get_model(X_train, y_train)\n",
    "\n",
    "datetimes = get_first_cube_datetimes(get_data(experiment)[3])\n",
    "\n",
    "print(\"Nr. of months:\", len(datetimes))\n",
    "print(\"Nr. of years:\", len(datetimes) / 12)\n",
    "print(\"30% of years:\", 0.3 * len(datetimes) / 12)\n",
    "print(\"First time:\", datetimes[0].year, datetimes[0].month)\n",
    "print(\"Last time:\", datetimes[-1].year, datetimes[-1].month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_scores = get_model_scores(model, X_test, X_train, y_test, y_train)\n",
    "normal_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go from DataFrame and Series back to MaskedArrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_valid_indices = np.where(~master_mask.ravel())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_y = np.ma.MaskedArray(np.zeros_like(master_mask, dtype=np.float64), mask=True)\n",
    "mm_y.ravel()[mm_valid_indices] = endog_data.values\n",
    "\n",
    "mm_X_data = {}\n",
    "for column in tqdm(exog_data.columns):\n",
    "    mm_X_data[column] = np.ma.MaskedArray(\n",
    "        np.zeros_like(master_mask, dtype=np.float64), mask=True\n",
    "    )\n",
    "    mm_X_data[column].ravel()[mm_valid_indices] = exog_data[column].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ignore some years, refit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_fitting(test_years):\n",
    "    temporal_train_inds = []\n",
    "    temporal_test_inds = []\n",
    "    train_years = []\n",
    "    for i, datetime in enumerate(datetimes):\n",
    "        if datetime.year in test_years:\n",
    "            temporal_test_inds.append(i)\n",
    "        else:\n",
    "            train_years.append(datetime.year)\n",
    "            temporal_train_inds.append(i)\n",
    "\n",
    "    train_years = tuple(sorted(set(train_years)))\n",
    "\n",
    "    print(\"test years:\", test_years)\n",
    "    print(\"train years:\", train_years)\n",
    "    print(\"Nr. test inds:\", len(temporal_test_inds))\n",
    "    print(\"Nr. train inds:\", len(temporal_train_inds))\n",
    "    assert len(temporal_test_inds) + len(temporal_train_inds) == len(datetimes)\n",
    "    print(f\"Test % of total: {100 * len(temporal_test_inds) / len(datetimes):0.1f}\")\n",
    "\n",
    "    temporal_X_train_data = {}\n",
    "    temporal_X_test_data = {}\n",
    "\n",
    "    for variable, mm_variable in mm_X_data.items():\n",
    "        temporal_mm_X_train_data_variable = mm_variable[temporal_train_inds]\n",
    "        temporal_X_train_data[variable] = temporal_mm_X_train_data_variable.data[\n",
    "            ~temporal_mm_X_train_data_variable.mask\n",
    "        ]\n",
    "\n",
    "        temporal_mm_X_test_data_variable = mm_variable[temporal_test_inds]\n",
    "        temporal_X_test_data[variable] = temporal_mm_X_test_data_variable.data[\n",
    "            ~temporal_mm_X_test_data_variable.mask\n",
    "        ]\n",
    "\n",
    "    temporal_X_train = pd.DataFrame(temporal_X_train_data)\n",
    "    temporal_X_test = pd.DataFrame(temporal_X_test_data)\n",
    "\n",
    "    del temporal_X_train_data\n",
    "    del temporal_X_test_data\n",
    "    gc.collect()\n",
    "\n",
    "    temporal_train_mm_y = mm_y[temporal_train_inds]\n",
    "    temporal_test_mm_y = mm_y[temporal_test_inds]\n",
    "\n",
    "    temporal_y_train = pd.Series(\n",
    "        temporal_train_mm_y.data[~temporal_train_mm_y.mask], name=endog_data.name\n",
    "    )\n",
    "    temporal_y_test = pd.Series(\n",
    "        temporal_test_mm_y.data[~temporal_test_mm_y.mask], name=endog_data.name\n",
    "    )\n",
    "\n",
    "    temporal_model = get_model(\n",
    "        temporal_X_train,\n",
    "        temporal_y_train,\n",
    "        parallel_backend_call=partial(\n",
    "            parallel_backend, \"threading\", n_jobs=get_ncpus()\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    temporal_scores = get_model_scores(\n",
    "        temporal_model,\n",
    "        temporal_X_test,\n",
    "        temporal_X_train,\n",
    "        temporal_y_test,\n",
    "        temporal_y_train,\n",
    "    )\n",
    "    print(temporal_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_years = tuple(range(2009, 2013))\n",
    "temporal_fitting(test_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_years = tuple(range(2016, 2020))\n",
    "temporal_fitting(test_years)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
