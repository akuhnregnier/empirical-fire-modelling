{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from joblib import parallel_backend\n",
    "from wildfires.analysis import cube_plotting\n",
    "from wildfires.dask_cx1 import DaskRandomForestRegressor\n",
    "from wildfires.data import regions_GFED\n",
    "from wildfires.utils import match_shape\n",
    "\n",
    "from empirical_fire_modelling.configuration import Experiment\n",
    "from empirical_fire_modelling.data import get_data\n",
    "from empirical_fire_modelling.utils import get_client, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gfed_regions = regions_GFED()\n",
    "gfed_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cube_plotting(gfed_regions, fig=plt.figure(figsize=(14, 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_client(fallback=True, fallback_threaded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endog_data, exog_data, master_mask = get_data(Experiment.ALL)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(~master_mask), endog_data.shape, exog_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values are either all masked or all unmasked at each location, which is goood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(np.sum(master_mask, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.all(master_mask[:1] == master_mask, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_data(data_1d, master_mask):\n",
    "    \"\"\"Go from 1D data to data on a map, defined by master_mask.\"\"\"\n",
    "    map_data = np.ma.MaskedArray(\n",
    "        np.zeros_like(master_mask, dtype=np.float64), mask=np.ones_like(master_mask)\n",
    "    )\n",
    "    map_data[~master_mask] = data_1d\n",
    "    return map_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gfed_region_cv_splits(X, y):\n",
    "    \"\"\"Split X and y according to the GFED regions.\"\"\"\n",
    "    ignore_regions = [\"Ocean\"]\n",
    "    for region_name, region_code in gfed_regions.attributes[\"region_codes\"].items():\n",
    "        if region_name in ignore_regions:\n",
    "            continue\n",
    "\n",
    "        # Select the region as the hold-out data.\n",
    "        hold_out_selection = (\n",
    "            match_shape(gfed_regions.data == region_code, master_mask.shape)\n",
    "            & ~master_mask\n",
    "        )\n",
    "        train_selection = (\n",
    "            match_shape(gfed_regions.data != region_code, master_mask.shape)\n",
    "            & ~master_mask\n",
    "        )\n",
    "\n",
    "        # Transform X, y to 3D arrays before selecting using the above masks.\n",
    "        mm_y = get_map_data(y.values, master_mask)\n",
    "\n",
    "        hold_out_y = mm_y.data[hold_out_selection]\n",
    "        train_y = mm_y.data[train_selection]\n",
    "\n",
    "        # Repeat for all column in X.\n",
    "\n",
    "        hold_out_X_data = {}\n",
    "        train_X_data = {}\n",
    "        for col in X:\n",
    "            mm_x_col = get_map_data(X[col].values, master_mask)\n",
    "\n",
    "            hold_out_X_data[col] = mm_x_col.data[hold_out_selection]\n",
    "            train_X_data[col] = mm_x_col.data[train_selection]\n",
    "\n",
    "        hold_out_X = pd.DataFrame(hold_out_X_data)\n",
    "        train_X = pd.DataFrame(train_X_data)\n",
    "\n",
    "        yield region_name, train_X, hold_out_X, train_y, hold_out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_name, train_X, hold_out_X, train_y, hold_out_y in get_gfed_region_cv_splits(\n",
    "    exog_data, endog_data\n",
    "):\n",
    "    print(region_name, train_X.shape, hold_out_X.shape, train_y.shape, hold_out_y.shape)\n",
    "    rf = DaskRandomForestRegressor(n_estimators=32, max_depth=15)\n",
    "    with parallel_backend(\"dask\"):\n",
    "        rf.fit(train_X, train_y)\n",
    "    print(rf.score(hold_out_X, hold_out_y))\n",
    "    print(rf.score(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_name, train_X, hold_out_X, train_y, hold_out_y in get_gfed_region_cv_splits(\n",
    "    exog_data, endog_data\n",
    "):\n",
    "    print(region_name, train_X.shape, hold_out_X.shape, train_y.shape, hold_out_y.shape)\n",
    "    rf = DaskRandomForestRegressor(n_estimators=32, max_depth=8)\n",
    "    with parallel_backend(\"dask\"):\n",
    "        rf.fit(train_X, train_y)\n",
    "    print(rf.score(hold_out_X, hold_out_y))\n",
    "    print(rf.score(train_X, train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train_y, bins=30)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(hold_out_y, bins=30)\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_mask_single = master_mask[0]\n",
    "valid_indices = np.where(~master_mask_single.ravel())[0]\n",
    "n_valid_indices = len(valid_indices)\n",
    "n_train = int(n_valid_indices * 0.7)\n",
    "n_test = n_valid_indices - n_train\n",
    "print(n_train, n_test, n_valid_indices)\n",
    "\n",
    "shuffled_indices = valid_indices.copy()\n",
    "np.random.default_rng(0).shuffle(shuffled_indices)\n",
    "\n",
    "train_indices = shuffled_indices[:n_train]\n",
    "test_indices = shuffled_indices[n_train:]\n",
    "\n",
    "train_mask_single = np.ones_like(master_mask_single)\n",
    "train_mask_single.ravel()[train_indices] = False\n",
    "\n",
    "test_mask_single = np.ones_like(master_mask_single)\n",
    "test_mask_single.ravel()[test_indices] = False\n",
    "\n",
    "train_y = get_map_data(endog_data.values, master_mask)[\n",
    "    match_shape(~train_mask_single, master_mask.shape)\n",
    "]\n",
    "test_y = get_map_data(endog_data.values, master_mask)[\n",
    "    match_shape(~test_mask_single, master_mask.shape)\n",
    "]\n",
    "\n",
    "train_X_data = {}\n",
    "test_X_data = {}\n",
    "\n",
    "for col in tqdm(exog_data.columns):\n",
    "    train_X_data[col] = get_map_data(exog_data[col].values, master_mask)[\n",
    "        match_shape(~train_mask_single, master_mask.shape)\n",
    "    ]\n",
    "    test_X_data[col] = get_map_data(exog_data[col].values, master_mask)[\n",
    "        match_shape(~test_mask_single, master_mask.shape)\n",
    "    ]\n",
    "\n",
    "train_X = pd.DataFrame(train_X_data)\n",
    "test_X = pd.DataFrame(test_X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cube_plotting(train_mask_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cube_plotting(test_mask_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = cube_plotting(master_mask_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = DaskRandomForestRegressor(n_estimators=10, max_depth=15)\n",
    "with parallel_backend(\"dask\"):\n",
    "    rf.fit(train_X, train_y)\n",
    "print(rf.score(test_X, test_y))\n",
    "print(rf.score(train_X, train_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
