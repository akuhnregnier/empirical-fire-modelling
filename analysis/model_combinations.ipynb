{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import warnings\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "from loguru import logger as loguru_logger\n",
    "\n",
    "from empirical_fire_modelling import variable\n",
    "from empirical_fire_modelling.analysis.model_combinations import (\n",
    "    cached_multiple_combinations,\n",
    ")\n",
    "from empirical_fire_modelling.configuration import Experiment, n_splits\n",
    "from empirical_fire_modelling.data import get_experiment_split_data\n",
    "from empirical_fire_modelling.logging_config import enable_logging\n",
    "from empirical_fire_modelling.utils import tqdm\n",
    "\n",
    "mpl.rc_file(\"matplotlibrc\")\n",
    "\n",
    "loguru_logger.enable(\"alepython\")\n",
    "loguru_logger.remove()\n",
    "loguru_logger.add(sys.stderr, level=\"WARNING\")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "enable_logging(level=\"WARNING\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", \".*Collapsing a non-contiguous coordinate.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*DEFAULT_SPHERICAL_EARTH_RADIUS.*\")\n",
    "warnings.filterwarnings(\"ignore\", \".*guessing contiguous bounds.*\")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\", 'Setting feature_perturbation = \"tree_path_dependent\".*'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training and test data for all variables.\n",
    "get_experiment_split_data.check_in_store(Experiment.ALL)\n",
    "X_train, X_test, y_train, y_test = get_experiment_split_data(Experiment.ALL)\n",
    "\n",
    "shifts = (0, 1, 3, 6, 9)\n",
    "assert all(shift in variable.lags for shift in shifts)\n",
    "\n",
    "veg_lags = tuple(\n",
    "    tuple(\n",
    "        [\n",
    "            var_factory[shift]\n",
    "            for var_factory in variable.feature_categories[variable.Category.VEGETATION]\n",
    "        ]\n",
    "    )\n",
    "    for shift in shifts\n",
    ")\n",
    "\n",
    "assert all(feature in X_train for unpacked in veg_lags for feature in unpacked)\n",
    "assert all(feature in X_test for unpacked in veg_lags for feature in unpacked)\n",
    "\n",
    "common_vars = (\n",
    "    variable.DRY_DAY_PERIOD[0],\n",
    "    variable.MAX_TEMP[0],\n",
    "    variable.PFT_CROP[0],\n",
    "    variable.DRY_DAY_PERIOD[1],\n",
    "    variable.DRY_DAY_PERIOD[3],\n",
    "    variable.DRY_DAY_PERIOD[9],\n",
    "    variable.POPD[0],\n",
    "    variable.DRY_DAY_PERIOD[6],\n",
    "    variable.LIGHTNING[0],\n",
    "    variable.DIURNAL_TEMP_RANGE[0],\n",
    ")\n",
    "\n",
    "combinations = [\n",
    "    (\n",
    "        *common_vars,\n",
    "        *veg_lag_product,\n",
    "    )\n",
    "    for veg_lag_product in product(*veg_lags)\n",
    "]\n",
    "\n",
    "assert all(len(combination) == 15 for combination in combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cached data for all combinations / splits.\n",
    "\n",
    "# Get training and test data for all variables.\n",
    "get_experiment_split_data.check_in_store(Experiment.ALL)\n",
    "X_all, _, y, _ = get_experiment_split_data(Experiment.ALL)\n",
    "combined_scores = cached_multiple_combinations(X_all, y, combinations, range(n_splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_scores = {}\n",
    "for variables, combination_data in tqdm(combined_scores.items()):\n",
    "    # Combine the different CV splits.\n",
    "    test_r2s = []\n",
    "    train_r2s = []\n",
    "\n",
    "    for cv_data in combination_data.values():\n",
    "        for key, val in cv_data.items():\n",
    "            if \"test_score\" in key:\n",
    "                test_r2s.append(val[\"r2\"])\n",
    "            elif \"train_score\" in key:\n",
    "                train_r2s.append(val[\"r2\"])\n",
    "\n",
    "    assert len(test_r2s) == len(train_r2s) == n_splits\n",
    "    processed_scores[\", \".join([str(v) for v in variables if v not in common_vars])] = {\n",
    "        \"test_mean\": np.mean(test_r2s),\n",
    "        \"test_std\": np.std(test_r2s),\n",
    "        \"train_mean\": np.mean(train_r2s),\n",
    "        \"train_std\": np.std(train_r2s),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df = pd.DataFrame(processed_scores).T.sort_values(\"test_mean\", ascending=False)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = {}\n",
    "for key in [\"FAPAR\", \"LAI\", \"SIF\", \"VOD\"]:\n",
    "    agg_data[key] = score_df[[key in i for i in score_df.index]][\"test_mean\"]\n",
    "_ = pd.DataFrame(agg_data).boxplot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:wildfires] *",
   "language": "python",
   "name": "conda-env-wildfires-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
